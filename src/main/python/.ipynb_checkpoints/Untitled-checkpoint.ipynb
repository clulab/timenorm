{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffac397e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bulut/miniforge3/envs/timenorm/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Reusing dataset conll2003 (/Users/bulut/.cache/huggingface/datasets/conll2003/conll2003/1.0.0/63f4ebd1bcb7148b1644497336fd74643d4ce70123334431a3c053b7ee4e96ee)\n",
      "100%|████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 222.91it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer\n",
    "from timenorm_data_provider import TimeDataProvider\n",
    "dataset = load_dataset(\"conll2003\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cca3124e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aff91247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (1236 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "relation to extract is:  Sub-Interval\n",
      "./example-data/train/ID032_clinic_094/ID032_clinic_094\n",
      "./example-data/train/ID027_path_080/ID027_path_080\n",
      "./example-data/train/ID025_clinic_073/ID025_clinic_073\n",
      "the entity that is linked does not exist in the document\n",
      "0/116 is done\n",
      "Skipping token types: 'ment [today] with' {'Calendar-Interval', 'This'}\n",
      "Skipping token types: 's of [Friday], Sep' {'Day-Of-Week', 'Intersection'}\n",
      "Skipping token types: 's of [Friday], Sep' {'Day-Of-Week', 'Intersection'}\n",
      "Skipping token types: 'Rate=[20] /min' {'Frequency', 'Number'}\n",
      "Skipping token types: 'Rate=[78] /min' {'Frequency', 'Number'}\n",
      "Skipping token types: 'r to [today]).  A' {'Calendar-Interval', 'This'}\n",
      "Skipping token types: 'that [today] or f' {'Calendar-Interval', 'This'}\n",
      "Skipping token types: 'hing [tomorrow] morn' {'Calendar-Interval', 'Intersection', 'Next'}\n",
      "Skipping token types: 'gery [tomorrow].  Sh' {'Calendar-Interval', 'Next'}\n",
      "100/116 is done\n",
      "Skipping token types: 's of [Wednesday], Apr' {'Day-Of-Week', 'Intersection'}\n",
      "Skipping token types: 's of [Wednesday], Apr' {'Day-Of-Week', 'Intersection'}\n",
      "Skipping token types: 'Rate=[16] /min' {'Frequency', 'Number'}\n",
      "Skipping token types: 'Rate=[66] /min' {'Frequency', 'Number'}\n",
      "dataset has been created\n"
     ]
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"roberta-base\", use_fast=True)\n",
    "data_loader = TimeDataProvider(corpus_dir=\"./example-data\")\n",
    "relation_to_extract = 'Sub-Interval'\n",
    "distances = [\n",
    "    '-6',\n",
    "    '-5',\n",
    "    '-4',\n",
    "    '-3',\n",
    "    '-2',\n",
    "    '-1',\n",
    "    'None',\n",
    "    '1',\n",
    "    '2',\n",
    "    '3',\n",
    "    '4',\n",
    "]\n",
    "f = open('./example-data/types.txt')\n",
    "lines = f.readlines()\n",
    "types = []\n",
    "for line in lines:\n",
    "    types.append(line.replace(\"\\n\", \"\"))\n",
    "inputs, labels_type, labels_distance = data_loader.read_data_to_distance_format(tokenizer, relation_to_extract, distances, types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e8d2d09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(inputs['input_ids']) == type(labels_type) == type(labels_distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9bfbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"a\": [1, 2, 3]}\n",
    "validation_dict = {\"a\": [3, 4, 5]}\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "validation_dataset = Dataset.from_dict(validation_dict)\n",
    "dataset_dict = {'train': train_dataset, 'validation': validation_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae878bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "DatasetDict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df594feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dict = {\"input_ids\": inputs['input_ids'], \"labels_type\": labels_type, \"labels_distance\": labels_distance}\n",
    "train_dataset = Dataset.from_dict(train_dict)\n",
    "dataset_dict = {'train': train_dataset}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4e38dfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'labels_type', 'labels_distance'],\n",
       "        num_rows: 116\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DatasetDict(dataset_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb4b152",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(inputs['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d850a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0f3eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00655715",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79fd967",
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in inputs['input_ids']:\n",
    "    for token in sent:\n",
    "        print(token.numpy().item())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1c8765",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe5993f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils_ import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68df6d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = 'pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a63c992",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset = prepare_dataset(dataset, task_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a70a0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ed4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_train_dataset = tokenized_dataset[\"train\"].shuffle(seed=42).select(range(len(tokenized_dataset[\"train\"])))\n",
    "train_dataloader = DataLoader(shuffled_train_dataset, batch_size=train_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbb3a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in shuffled_train_dataset.features.keys():\n",
    "    if col != 'input_ids' and col != 'labels' and col != 'attention_mask':\n",
    "        shuffled_train_dataset = shuffled_train_dataset.remove_columns([col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9532a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(tokenized_dataset[\"train\"], batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0458ef2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468225be",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['train']['labels'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938cd0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_dataset['train']['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eb1787",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = dataset[\"train\"].features[f\"{task_name}_tags\"].feature.names\n",
    "num_labels = len(label_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f20098",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(pretrained_model_name_or_path=model_name, \n",
    "                                                                num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9c7018",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcae3460",
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch in train_dataloader:\n",
    "    model.train()\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    print(batch)\n",
    "    outputs = model.forward(input_ids=batch['input_ids'], labels=batch['labels'])\n",
    "    print(outputs)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181cf242",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd894386",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb688fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(shuffled_train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be56394",
   "metadata": {},
   "outputs": [],
   "source": [
    "439*32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f875d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c65a11de",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
